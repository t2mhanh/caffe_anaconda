I0912 21:31:03.795212 31271 caffe.cpp:218] Using GPUs 0
I0912 21:31:03.803537 31271 caffe.cpp:223] GPU 0: GeForce GTX TITAN X
I0912 21:31:04.675658 31271 solver.cpp:44] Initializing solver from parameters: 
test_iter: 2
test_interval: 50
base_lr: 0.001
display: 50
max_iter: 650000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 500
snapshot_prefix: "/usr/not-backed-up/1_convlstm/mnist_GlobalWta"
solver_mode: GPU
device_id: 0
test_compute_loss: true
net: "examples/mnist_wta_autoencoder/mnist_wta.prototxt"
train_state {
  level: 0
  stage: ""
}
test_state {
  stage: "test-on-test"
}
I0912 21:31:04.676039 31271 solver.cpp:87] Creating training net from net file: examples/mnist_wta_autoencoder/mnist_wta.prototxt
I0912 21:31:04.678004 31271 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0912 21:31:04.678020 31271 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0912 21:31:04.678133 31271 net.cpp:51] Initializing net from parameters: 
name: "MNISTWTA"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0039215684
    mean_file: "/usr/not-backed-up/1_convlstm/mnist/mean_image.binaryproto"
  }
  data_param {
    source: "/usr/not-backed-up/1_convlstm/mnist/mnist_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "wta"
  type: "SpatialWta"
  bottom: "conv3"
  top: "wta"
  spatial_wta_param {
    global_wta: true
  }
}
layer {
  name: "deconv"
  type: "Deconvolution"
  bottom: "wta"
  top: "deconv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 5
    kernel_size: 11
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "Python"
  bottom: "deconv"
  bottom: "data"
  top: "l2_error"
  loss_weight: 1
  python_param {
    module: "pyloss"
    layer: "EuclideanLossLayer"
  }
}
I0912 21:31:04.678221 31271 layer_factory.hpp:77] Creating layer data
I0912 21:31:04.709312 31271 db_lmdb.cpp:35] Opened lmdb /usr/not-backed-up/1_convlstm/mnist/mnist_train_lmdb
I0912 21:31:04.712954 31271 net.cpp:84] Creating Layer data
I0912 21:31:04.712991 31271 net.cpp:380] data -> data
I0912 21:31:04.713027 31271 data_transformer.cpp:25] Loading mean file from: /usr/not-backed-up/1_convlstm/mnist/mean_image.binaryproto
I0912 21:31:04.714161 31271 data_layer.cpp:45] output data size: 100,1,28,28
I0912 21:31:04.721946 31271 net.cpp:122] Setting up data
I0912 21:31:04.721966 31271 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0912 21:31:04.721971 31271 net.cpp:137] Memory required for data: 313600
I0912 21:31:04.721981 31271 layer_factory.hpp:77] Creating layer data_data_0_split
I0912 21:31:04.722020 31271 net.cpp:84] Creating Layer data_data_0_split
I0912 21:31:04.722030 31271 net.cpp:406] data_data_0_split <- data
I0912 21:31:04.722062 31271 net.cpp:380] data_data_0_split -> data_data_0_split_0
I0912 21:31:04.722077 31271 net.cpp:380] data_data_0_split -> data_data_0_split_1
I0912 21:31:04.722141 31271 net.cpp:122] Setting up data_data_0_split
I0912 21:31:04.722153 31271 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0912 21:31:04.722162 31271 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0912 21:31:04.722182 31271 net.cpp:137] Memory required for data: 940800
I0912 21:31:04.722187 31271 layer_factory.hpp:77] Creating layer conv1
I0912 21:31:04.722211 31271 net.cpp:84] Creating Layer conv1
I0912 21:31:04.722218 31271 net.cpp:406] conv1 <- data_data_0_split_0
I0912 21:31:04.722239 31271 net.cpp:380] conv1 -> conv1
I0912 21:31:04.724025 31271 net.cpp:122] Setting up conv1
I0912 21:31:04.724040 31271 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0912 21:31:04.724045 31271 net.cpp:137] Memory required for data: 21011200
I0912 21:31:04.724061 31271 layer_factory.hpp:77] Creating layer relu1
I0912 21:31:04.724071 31271 net.cpp:84] Creating Layer relu1
I0912 21:31:04.724078 31271 net.cpp:406] relu1 <- conv1
I0912 21:31:04.724089 31271 net.cpp:367] relu1 -> conv1 (in-place)
I0912 21:31:04.724107 31271 net.cpp:122] Setting up relu1
I0912 21:31:04.724117 31271 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0912 21:31:04.724125 31271 net.cpp:137] Memory required for data: 41081600
I0912 21:31:04.724130 31271 layer_factory.hpp:77] Creating layer conv2
I0912 21:31:04.724143 31271 net.cpp:84] Creating Layer conv2
I0912 21:31:04.724148 31271 net.cpp:406] conv2 <- conv1
I0912 21:31:04.724155 31271 net.cpp:380] conv2 -> conv2
I0912 21:31:04.725188 31271 net.cpp:122] Setting up conv2
I0912 21:31:04.725201 31271 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0912 21:31:04.725208 31271 net.cpp:137] Memory required for data: 61152000
I0912 21:31:04.725219 31271 layer_factory.hpp:77] Creating layer relu2
I0912 21:31:04.725230 31271 net.cpp:84] Creating Layer relu2
I0912 21:31:04.725235 31271 net.cpp:406] relu2 <- conv2
I0912 21:31:04.725267 31271 net.cpp:367] relu2 -> conv2 (in-place)
I0912 21:31:04.725293 31271 net.cpp:122] Setting up relu2
I0912 21:31:04.725317 31271 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0912 21:31:04.725356 31271 net.cpp:137] Memory required for data: 81222400
I0912 21:31:04.725378 31271 layer_factory.hpp:77] Creating layer conv3
I0912 21:31:04.725412 31271 net.cpp:84] Creating Layer conv3
I0912 21:31:04.725436 31271 net.cpp:406] conv3 <- conv2
I0912 21:31:04.725467 31271 net.cpp:380] conv3 -> conv3
I0912 21:31:04.726995 31271 net.cpp:122] Setting up conv3
I0912 21:31:04.727010 31271 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0912 21:31:04.727013 31271 net.cpp:137] Memory required for data: 101292800
I0912 21:31:04.727022 31271 layer_factory.hpp:77] Creating layer relu3
I0912 21:31:04.727032 31271 net.cpp:84] Creating Layer relu3
I0912 21:31:04.727036 31271 net.cpp:406] relu3 <- conv3
I0912 21:31:04.727041 31271 net.cpp:367] relu3 -> conv3 (in-place)
I0912 21:31:04.727048 31271 net.cpp:122] Setting up relu3
I0912 21:31:04.727056 31271 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0912 21:31:04.727059 31271 net.cpp:137] Memory required for data: 121363200
I0912 21:31:04.727063 31271 layer_factory.hpp:77] Creating layer wta
I0912 21:31:04.727074 31271 net.cpp:84] Creating Layer wta
I0912 21:31:04.727079 31271 net.cpp:406] wta <- conv3
I0912 21:31:04.727084 31271 net.cpp:380] wta -> wta
I0912 21:31:04.727128 31271 net.cpp:122] Setting up wta
I0912 21:31:04.727133 31271 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0912 21:31:04.727138 31271 net.cpp:137] Memory required for data: 141433600
I0912 21:31:04.727140 31271 layer_factory.hpp:77] Creating layer deconv
I0912 21:31:04.727152 31271 net.cpp:84] Creating Layer deconv
I0912 21:31:04.727157 31271 net.cpp:406] deconv <- wta
I0912 21:31:04.727169 31271 net.cpp:380] deconv -> deconv
I0912 21:31:04.727900 31271 net.cpp:122] Setting up deconv
I0912 21:31:04.727915 31271 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0912 21:31:04.727919 31271 net.cpp:137] Memory required for data: 141747200
I0912 21:31:04.727926 31271 layer_factory.hpp:77] Creating layer loss
ImportError: No module named pyloss
